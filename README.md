# ğŸš¢ Ship Telemetry Monitoring System

A real-time telemetry monitoring platform for maritime vessels, built with **Apache Airflow 3.0.0**, **PySpark**, **Streamlit**, and **DuckDB**.

---

## ğŸ§­ Overview

This system provides real-time monitoring and analytics for ship telemetry data, including:

- ğŸ—ºï¸ Location and movement tracking  
- â›½ Fuel consumption monitoring  
- ğŸŒ¦ï¸ Weather condition tracking  
- âš™ï¸ Engine performance metrics  
- ğŸš¨ Real-time alerts and notifications  

---

## ğŸ“Š Dashboard Preview

<p align="center">
  <img src="assets/Overview.png" alt="Dashboard Overview" width="600"/>
  <br/>
  <img src="assets/CII.png" alt="Carbon Intensity Indicator" width="600"/>
  <br/>
  <img src="assets/Distance.png" alt="Distance and Performance Metrics" width="600"/>
</p>

---

## ğŸ§± Architecture

The system consists of three major components:

1. **Stream Processor** â€“ PySpark pipeline processing telemetry in near real-time  
2. **Monitoring Dashboard** â€“ Interactive insights via Streamlit  
3. **Orchestration Layer** â€“ Apache Airflow manages scheduling and monitoring

---

## âš™ï¸ Tech Stack

| Layer             | Technology               |
|------------------|--------------------------|
| Orchestration     | Apache Airflow 3.0.0     |
| Stream Processing | PySpark                  |
| Data Storage      | DuckDB                   |
| Dashboard         | Streamlit                |
| Containerization  | Docker + Docker Compose  |

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/mickyansLK/ship-telemetry-project.git
cd ship-telemetry-project

python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

AIRFLOW_HOME=$(pwd)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=ship_telemetry
EXPORT_PATH=warehouse/default
CHECKPOINT_PATH=checkpoints
DASHBOARD_REFRESH_INTERVAL=10
CACHE_TTL=30

export AIRFLOW_HOME=$(pwd)
airflow standalone

streamlit run dashboard.py

ship-telemetry-project/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ ship_telemetry_dag.py        # Airflow DAG definition
â”œâ”€â”€ stream_processor.py              # Real-time Spark processing
â”œâ”€â”€ dashboard.py                     # Streamlit dashboard
â”œâ”€â”€ simulate_sensors.py              # Data simulation logic
â”œâ”€â”€ config.py                        # Environment configuration
â”œâ”€â”€ requirements.txt                 # Project dependencies
â”œâ”€â”€ airflow.cfg                      # Airflow configuration
â””â”€â”€ assets/                          # Dashboard images

[core]
dags_folder = dags
load_examples = False

[api]
auth_backend = airflow.api.auth.backend.basic_auth
jwt_secret = your-secure-secret
port = 8080
workers = 4
host = 0.0.0.0

[webserver]
secret_key = your-webserver-secret
